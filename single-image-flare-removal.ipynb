{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# for TPU\n!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n!python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev","metadata":{"execution":{"iopub.status.busy":"2021-11-09T09:46:17.068785Z","iopub.execute_input":"2021-11-09T09:46:17.069609Z","iopub.status.idle":"2021-11-09T09:47:19.628514Z","shell.execute_reply.started":"2021-11-09T09:46:17.069046Z","shell.execute_reply":"2021-11-09T09:47:19.627309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision\nimport torch.nn.functional as F\nimport numpy as np \nfrom matplotlib import pyplot as plt\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nfrom torch.utils.data import random_split\nfrom torchvision import models,datasets\nimport os\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nfrom PIL import Image","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-18T13:15:44.925522Z","iopub.execute_input":"2022-03-18T13:15:44.92587Z","iopub.status.idle":"2022-03-18T13:15:44.931967Z","shell.execute_reply.started":"2022-03-18T13:15:44.925837Z","shell.execute_reply":"2022-03-18T13:15:44.930821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = \"cuda\"\nelse:\n    device = \"cpu\"\nprint(f\"# Using device: {device}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-18T13:16:16.399334Z","iopub.execute_input":"2022-03-18T13:16:16.399667Z","iopub.status.idle":"2022-03-18T13:16:16.474736Z","shell.execute_reply.started":"2022-03-18T13:16:16.399634Z","shell.execute_reply":"2022-03-18T13:16:16.473739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-03-18T13:16:18.031958Z","iopub.execute_input":"2022-03-18T13:16:18.03231Z","iopub.status.idle":"2022-03-18T13:16:18.03674Z","shell.execute_reply.started":"2022-03-18T13:16:18.032275Z","shell.execute_reply":"2022-03-18T13:16:18.035611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Hyperparamters\nBATCH_SIZE = 8","metadata":{"execution":{"iopub.status.busy":"2022-03-18T13:16:25.390171Z","iopub.execute_input":"2022-03-18T13:16:25.390492Z","iopub.status.idle":"2022-03-18T13:16:25.393954Z","shell.execute_reply.started":"2022-03-18T13:16:25.390462Z","shell.execute_reply":"2022-03-18T13:16:25.393115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_transform = transforms.Compose([\n        transforms.Resize((256, 256)),\n        #transforms.RandomResizedCrop(256),\n        transforms.RandomHorizontalFlip(),\n        #transforms.ColorJitter(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])\n])\n\ntest_transform = transforms.Compose([\n        transforms.Resize((256,256)),\n        #transforms.CenterCrop(256),\n        transforms.ToTensor(),\n        transforms.Normalize([0.5], [0.5])\n    ])","metadata":{"execution":{"iopub.status.busy":"2022-03-18T13:16:26.524875Z","iopub.execute_input":"2022-03-18T13:16:26.525334Z","iopub.status.idle":"2022-03-18T13:16:26.531133Z","shell.execute_reply.started":"2022-03-18T13:16:26.5253Z","shell.execute_reply":"2022-03-18T13:16:26.530121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Flare(Dataset):\n    def __init__(self, flare_dir, wf_dir, flare_img_, wf_img_, transform = None):\n        self.flare_dir = flare_dir\n        self.wf_dir = wf_dir\n        self.transform = transform\n        self.flare_l = flare_img_\n        self.wf_l = wf_img_\n        \n    def __len__(self):\n        return len(self.flare_l)\n    def __getitem__(self, idx):\n        f_img = Image.open(os.path.join(self.flare_dir, self.flare_l[idx])).convert(\"RGB\")\n        for i in self.wf_l:\n            if (self.flare_l[idx].split('.')[0][4:] == i.split('.')[0]):\n                wf_img = Image.open(os.path.join(self.wf_dir, i)).convert(\"RGB\")\n                break\n        f_img = self.transform(f_img)\n        wf_img = self.transform(wf_img)\n        \n        \n        return f_img, wf_img        ","metadata":{"execution":{"iopub.status.busy":"2022-03-18T13:16:27.922378Z","iopub.execute_input":"2022-03-18T13:16:27.922692Z","iopub.status.idle":"2022-03-18T13:16:27.93041Z","shell.execute_reply.started":"2022-03-18T13:16:27.922661Z","shell.execute_reply":"2022-03-18T13:16:27.929449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"flare_dir = '../input/dehazer/Flare/Flare_img'\nwf_dir = '../input/dehazer/Flare/Without_Flare_'\nflare_img = os.listdir(flare_dir)\nwf_img = os.listdir(wf_dir)\nwf_img.sort()\nflare_img.sort()\nprint(wf_img[0])\ntrain_ds = Flare(flare_dir, wf_dir, flare_img, wf_img, train_transform)\ntrain_loader = torch.utils.data.DataLoader(dataset=train_ds,\n                                           batch_size=BATCH_SIZE, \n                                           shuffle=True)\nprint(len(train_ds))","metadata":{"execution":{"iopub.status.busy":"2022-03-18T13:16:35.429951Z","iopub.execute_input":"2022-03-18T13:16:35.430262Z","iopub.status.idle":"2022-03-18T13:16:36.207281Z","shell.execute_reply.started":"2022-03-18T13:16:35.430233Z","shell.execute_reply":"2022-03-18T13:16:36.206429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fn = os.listdir(flare_dir)[:5000]\nf = os.listdir(wf_dir)[:5000]\nk = 0\nfor i in f:\n    if (fn[34].split('.')[0][4:] == i.split('.')[0]):\n        print(i.split('.')[0])\n    k+=1\n    #print(fn[4].split('.')[0][4:])\n    #print(i.split('.')[0])\n    #if (k==10):\n       # break","metadata":{"execution":{"iopub.status.busy":"2022-03-18T13:16:38.291863Z","iopub.execute_input":"2022-03-18T13:16:38.292186Z","iopub.status.idle":"2022-03-18T13:16:38.311826Z","shell.execute_reply.started":"2022-03-18T13:16:38.292157Z","shell.execute_reply":"2022-03-18T13:16:38.311066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i,l = next(iter(train_loader))\nprint(i.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T13:16:40.306106Z","iopub.execute_input":"2022-03-18T13:16:40.30643Z","iopub.status.idle":"2022-03-18T13:16:40.786377Z","shell.execute_reply.started":"2022-03-18T13:16:40.3064Z","shell.execute_reply":"2022-03-18T13:16:40.785457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy\nsamples, labels = iter(train_loader).next()\nplt.figure(figsize=(16,24))\ngrid_imgs = torchvision.utils.make_grid(samples.cpu(),normalize = True)\nnp_grid_imgs = grid_imgs.numpy()\n# in tensor, image is (batch, width, height), so you have to transpose it to (width, height, batch) in numpy to show it.\nplt.imshow(numpy.transpose(np_grid_imgs, (1,2,0)))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-18T13:16:43.272968Z","iopub.execute_input":"2022-03-18T13:16:43.273348Z","iopub.status.idle":"2022-03-18T13:16:44.162125Z","shell.execute_reply.started":"2022-03-18T13:16:43.273312Z","shell.execute_reply":"2022-03-18T13:16:44.157544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_eval(dataloader,model):\n    total = 0\n    correct = 0\n    for data in dataloader:\n      images, l = data\n      \n      images = images.to(device)\n      l = l.to(device)\n      \n      out = model(images)\n      max_val, preds = torch.max(out,dim=1)\n      \n      total += l.shape[0]                   \n      correct += (preds == l).sum().item()  \n      accuracy = (100 * correct)/total\n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2022-03-18T13:16:49.96688Z","iopub.execute_input":"2022-03-18T13:16:49.967233Z","iopub.status.idle":"2022-03-18T13:16:49.973405Z","shell.execute_reply.started":"2022-03-18T13:16:49.967191Z","shell.execute_reply":"2022-03-18T13:16:49.972431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correct = 0\na = torch.randn(2,3)\nb = torch.randn(2,3)\ncorrect += (a == b).sum()\nprint(correct)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T13:16:51.646954Z","iopub.execute_input":"2022-03-18T13:16:51.647266Z","iopub.status.idle":"2022-03-18T13:16:51.658852Z","shell.execute_reply.started":"2022-03-18T13:16:51.647236Z","shell.execute_reply":"2022-03-18T13:16:51.657781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResidualBlock(nn.Module):\n\n    def __init__(self):\n        super(ResidualBlock, self).__init__()\n        self.res_b1 = self.get_res_block(2)\n        self.res_b2 = self.get_res_block(2)\n        self.res_b3 = self.get_res_block(3)\n        self.res_b4 = self.get_res_block(4)\n        self.relu = nn.ReLU(inplace = True)\n    \n    def get_res_block(self, block_size = 1, in_dim = 128, out_dim = 128):\n        layers = []\n        for i in range(block_size + 1):\n            layers.append(nn.Conv2d(in_dim, out_dim, 3, padding = 1))\n            if i != block_size:\n                layers.append(nn.ReLU(inplace = True))\n        return nn.Sequential(*layers)\n        \n        \n    \n    def forward(self, image):\n        output = self.res_b1(image)\n        res_b1_image = self.relu(image + output)\n        \n        output = self.res_b2(res_b1_image)\n        res_b2_image = self.relu(res_b1_image + output)\n        \n        output = self.res_b3(res_b2_image)\n        res_b3_image = self.relu(res_b2_image + output)\n        \n        output = self.res_b4(res_b3_image)\n        res_b4_image = res_b3_image + output\n        \n        return res_b4_image","metadata":{"execution":{"iopub.status.busy":"2022-03-18T13:18:08.868386Z","iopub.execute_input":"2022-03-18T13:18:08.868702Z","iopub.status.idle":"2022-03-18T13:18:08.877665Z","shell.execute_reply.started":"2022-03-18T13:18:08.868671Z","shell.execute_reply":"2022-03-18T13:18:08.876728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GMAN(nn.Module):\n    def __init__(self, in_dim = 3, hidden_dim = 64):\n        super(GMAN, self).__init__()\n        self.relu = nn.ReLU(inplace = True)\n        self.gman = nn.Sequential(\n            nn.Conv2d(in_dim, hidden_dim, 3, padding = 1),\n            nn.ReLU(inplace = True),\n            nn.Conv2d(hidden_dim, hidden_dim, 3, padding = 1),\n            nn.ReLU(inplace = True),\n            nn.Conv2d(hidden_dim, hidden_dim * 2, 3, padding = 1, stride = 2),\n            nn.ReLU(inplace = True),\n            nn.Conv2d(hidden_dim * 2, hidden_dim * 2, 3, padding = 1, stride = 2),\n            nn.ReLU(inplace = True),\n            ResidualBlock(),\n            nn.ReLU(inplace = True),\n            nn.ConvTranspose2d(hidden_dim * 2, hidden_dim, 2, stride = 2),\n            nn.ConvTranspose2d(hidden_dim, hidden_dim, 2, stride = 2),\n            nn.Conv2d(hidden_dim, hidden_dim, 3, padding = 1),\n            nn.Conv2d(hidden_dim, in_dim, 3, padding = 1),\n        )\n    \n    \n    def forward(self, image):\n        return self.relu(image + self.gman(image))\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-03-18T13:18:09.882279Z","iopub.execute_input":"2022-03-18T13:18:09.882691Z","iopub.status.idle":"2022-03-18T13:18:09.897503Z","shell.execute_reply.started":"2022-03-18T13:18:09.882652Z","shell.execute_reply":"2022-03-18T13:18:09.89673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def init_weights(m):\n    if type(m) == nn.Conv2d or type(m) == nn.ConvTranspose2d:\n        torch.nn.init.normal_(m.weight, mean=0.0, std=0.008)\n        m.bias.data.fill_(0.01)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-18T13:18:11.169259Z","iopub.execute_input":"2022-03-18T13:18:11.169573Z","iopub.status.idle":"2022-03-18T13:18:11.175594Z","shell.execute_reply.started":"2022-03-18T13:18:11.169541Z","shell.execute_reply":"2022-03-18T13:18:11.174629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"net = GMAN().to(device)\nnet.apply(init_weights)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T13:18:13.123895Z","iopub.execute_input":"2022-03-18T13:18:13.124201Z","iopub.status.idle":"2022-03-18T13:18:17.492434Z","shell.execute_reply.started":"2022-03-18T13:18:13.124171Z","shell.execute_reply":"2022-03-18T13:18:17.49159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_image(hazy_image, gt_image, predicted_image):\n    \n    title = ['Flare Image', 'Ground Truth Image', 'Predicted']\n    \n    plt.figure(figsize=(15, 15))\n    \n    \n    display_list = [\n                        hazy_image.cpu().permute(1, 2, 0).numpy(),\n                        gt_image.cpu().permute(1, 2, 0).numpy(),\n                        predicted_image.detach().cpu().permute(1, 2, 0).numpy()\n                   ]\n    \n    \n    for i in range(3):\n        plt.subplot(1, 3, i+1)\n        plt.title(title[i])\n        plt.imshow(display_list[i])\n        plt.axis('off')\n        \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-18T13:18:17.493975Z","iopub.execute_input":"2022-03-18T13:18:17.494321Z","iopub.status.idle":"2022-03-18T13:18:17.501163Z","shell.execute_reply.started":"2022-03-18T13:18:17.494283Z","shell.execute_reply":"2022-03-18T13:18:17.500254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\ndef train(net, criterion, optimizer,num_epochs,scaler,sch):\n    for epoch in range(num_epochs):\n        print(\"Epoch:\",epoch+1)\n        print(\"LR: \", sch.get_last_lr())\n        loss_h = []\n        loop = tqdm(train_loader, leave = True)\n        for i, (flare,gt) in enumerate(loop):\n            #flare,gt = next(iter(train_loader))\n            with torch.cuda.amp.autocast():  \n                net.to(device)\n                flare = flare.to(device).to(torch.float16)\n                gt = gt.to(device).to(torch.float16)\n\n                output = net(flare)\n                #output = F.sigmoid(output)\n                output = output.to(device) \n            optimizer.zero_grad()\n            loss_i = criterion(output, gt)\n            #loss_f = criterion(output- gt, torch.zeros_like(gt))\n            loss = loss_i \n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n            loop.set_postfix(loss = loss.item())  \n            loss_h.append(loss.item())\n            \n        f, w = next(iter(train_loader))\n        sch.step()\n        with torch.no_grad():\n            #if (epoch%4 == 0):\n                print(\"LR:\", sch.get_last_lr())\n                grid_imgs = torchvision.utils.make_grid(f[:32].cpu(), normalize = True).numpy()\n                plt.figure(figsize=(16,16))\n                plt.imshow(np.transpose((grid_imgs),(1,2,0)))\n                plt.show()\n\n                o = net(f.to(device)).cpu()\n                grid_imgs1 = torchvision.utils.make_grid(o[:32], normalize = True).numpy()\n                plt.figure(figsize=(16,16))\n                plt.imshow(np.transpose((grid_imgs),(1,2,0)))\n                plt.show()\n\n                plt.plot(loss_h)\n                plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-18T13:21:30.70692Z","iopub.execute_input":"2022-03-18T13:21:30.707248Z","iopub.status.idle":"2022-03-18T13:21:30.719415Z","shell.execute_reply.started":"2022-03-18T13:21:30.70722Z","shell.execute_reply":"2022-03-18T13:21:30.718612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f,w = next(iter(train_loader))\nf = f.to(device).float()\nw = w.to(device).float()\ni = (f).detach()\n\nplt.figure(figsize=(16,16))\nimg_grid = torchvision.utils.make_grid(f[:32].cpu(),normalize = True)\nplt.imshow(np.transpose(img_grid,(1,2,0)))\nplt.show()\n\nplt.figure(figsize=(16,16))\nplt.title(\"Fake Images\")\nimg_grid = torchvision.utils.make_grid(i[:32].cpu(), normalize = True)\nplt.imshow(np.transpose(img_grid,(1,2,0)))\nplt.show()\n\nplt.figure(figsize=(16,16))\nimg_grid = torchvision.utils.make_grid(w[:32].cpu(),normalize = True)\nplt.imshow(np.transpose(img_grid,(1,2,0)))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-18T22:05:15.10168Z","iopub.execute_input":"2022-03-18T22:05:15.102073Z","iopub.status.idle":"2022-03-18T22:05:16.244089Z","shell.execute_reply.started":"2022-03-18T22:05:15.102032Z","shell.execute_reply":"2022-03-18T22:05:16.243159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 30\n#criterion = nn.BCEWithLogitsLoss()\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(net.parameters(), lr=1e-5)\nscaler = torch.cuda.amp.GradScaler()\n# Decay LR by a factor of 0.1 every several epochs\nsch = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma= 0.5)\n\ntrain(net, criterion, optimizer, num_epochs, scaler,sch)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-18T13:21:32.40471Z","iopub.execute_input":"2022-03-18T13:21:32.405073Z","iopub.status.idle":"2022-03-18T22:05:14.020375Z","shell.execute_reply.started":"2022-03-18T13:21:32.405042Z","shell.execute_reply":"2022-03-18T22:05:14.019249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"net_save_name = 'flare_UNET_40epochs.pt'\npath = F\".//{net_save_name}\" \ntorch.save(net.state_dict(), path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}