{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision\nimport torch.nn.functional as F\nimport numpy as np \nfrom matplotlib import pyplot as plt\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nfrom torch.utils.data import random_split\nfrom torchvision import models,datasets\nimport os\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nfrom PIL import Image\nfrom torch.autograd import Variable","metadata":{"execution":{"iopub.status.busy":"2021-11-08T06:26:44.495809Z","iopub.execute_input":"2021-11-08T06:26:44.496129Z","iopub.status.idle":"2021-11-08T06:26:45.702014Z","shell.execute_reply.started":"2021-11-08T06:26:44.496099Z","shell.execute_reply":"2021-11-08T06:26:45.701124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"USE_GPU = True\n\nif USE_GPU and torch.cuda.is_available():\n    print('using device: cuda')\nelse:\n    print('using device: cpu')\n\ndevice = torch.device(\"cuda:0\" if USE_GPU else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2021-11-08T06:26:45.703493Z","iopub.execute_input":"2021-11-08T06:26:45.703877Z","iopub.status.idle":"2021-11-08T06:26:45.775389Z","shell.execute_reply.started":"2021-11-08T06:26:45.703839Z","shell.execute_reply":"2021-11-08T06:26:45.774462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Hyperparamters\nBATCH_SIZE = 64","metadata":{"execution":{"iopub.status.busy":"2021-11-08T06:26:45.777559Z","iopub.execute_input":"2021-11-08T06:26:45.778174Z","iopub.status.idle":"2021-11-08T06:26:45.78579Z","shell.execute_reply.started":"2021-11-08T06:26:45.778134Z","shell.execute_reply":"2021-11-08T06:26:45.784998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_transform = transforms.Compose([\n        transforms.Resize((256, 256)),\n        #transforms.RandomResizedCrop(256),\n        transforms.RandomHorizontalFlip(),\n        #transforms.ColorJitter(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])\n])\n\ntest_transform = transforms.Compose([\n        transforms.Resize((256,256)),\n        #transforms.CenterCrop(256),\n        transforms.ToTensor(),\n        transforms.Normalize([0.5], [0.5])\n    ])","metadata":{"execution":{"iopub.status.busy":"2021-11-08T06:26:45.787847Z","iopub.execute_input":"2021-11-08T06:26:45.788264Z","iopub.status.idle":"2021-11-08T06:26:45.797017Z","shell.execute_reply.started":"2021-11-08T06:26:45.788225Z","shell.execute_reply":"2021-11-08T06:26:45.79614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Flare_Classifier(Dataset):\n    \n    def __init__(self,directory,filelist,c,transform = None):\n        self.filelist = filelist\n        self.directory = directory\n        self.c = c\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.filelist)\n    \n    def __getitem__(self,idx):\n        img =  Image.open(os.path.join(self.directory, self.filelist[idx])).convert(\"RGB\")\n        img = self.transform(img)\n        \n        if 'Flare_img' == self.c:\n            self.label = 0\n        elif 'Without_Flare_' == self.c:\n            self.label = 1\n        \n        img = img.numpy()\n        return img, self.label","metadata":{"execution":{"iopub.status.busy":"2021-11-08T06:26:45.798521Z","iopub.execute_input":"2021-11-08T06:26:45.79924Z","iopub.status.idle":"2021-11-08T06:26:45.80709Z","shell.execute_reply.started":"2021-11-08T06:26:45.799099Z","shell.execute_reply":"2021-11-08T06:26:45.806216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"parent_dir = '../input/flaredataset/Flare'\nclasses = ['Flare_img','Without_Flare_']\nworking_ds = None\nfor c in classes:\n    directory = os.path.join(parent_dir,c)\n    print(directory)\n    file_list = os.listdir(directory)\n    new = Flare_Classifier(directory,file_list,c,train_transform)\n    \n    if working_ds == None:\n        working_ds = new\n    else:\n        working_ds = ConcatDataset([working_ds,new])\n        \nprint(len(working_ds))","metadata":{"execution":{"iopub.status.busy":"2021-11-08T06:26:45.80829Z","iopub.execute_input":"2021-11-08T06:26:45.808731Z","iopub.status.idle":"2021-11-08T06:26:47.529506Z","shell.execute_reply.started":"2021-11-08T06:26:45.808688Z","shell.execute_reply":"2021-11-08T06:26:47.528605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_val_split(working_ds):\n    val_split = 0.05\n    l = float(len(working_ds))\n    m = int(val_split*l)\n    train_ds,val_ds = random_split(working_ds,[int(l)-m,m])\n    return train_ds,val_ds\n\ntrain_ds,val_ds = train_val_split(working_ds)\n\ntrain_loader_ = torch.utils.data.DataLoader(dataset=train_ds,\n                                           batch_size=BATCH_SIZE, \n                                           shuffle=True)\n\nval_loader_ = torch.utils.data.DataLoader(dataset=val_ds,\n                                           batch_size=BATCH_SIZE, \n                                           shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-08T06:26:47.530844Z","iopub.execute_input":"2021-11-08T06:26:47.53137Z","iopub.status.idle":"2021-11-08T06:26:47.553353Z","shell.execute_reply.started":"2021-11-08T06:26:47.531331Z","shell.execute_reply":"2021-11-08T06:26:47.552609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy\nsamples, labels = iter(train_loader_).next()\nplt.figure(figsize=(16,24))\ngrid_imgs = torchvision.utils.make_grid(samples[:24], normalize  = True)\nnp_grid_imgs = grid_imgs.numpy()\n# in tensor, image is (batch, width, height), so you have to transpose it to (width, height, batch) in numpy to show it.\nplt.imshow(numpy.transpose(np_grid_imgs, (1,2,0)))\nprint(labels)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-08T06:26:47.55622Z","iopub.execute_input":"2021-11-08T06:26:47.556533Z","iopub.status.idle":"2021-11-08T06:26:50.477649Z","shell.execute_reply.started":"2021-11-08T06:26:47.556508Z","shell.execute_reply":"2021-11-08T06:26:50.47689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fe = models.squeezenet1_0(pretrained=True)\nfor param in fe.parameters():\n\tparam.requires_grad = True\nclass ResNet18(nn.Module):\n  def __init__(self):\n    super(ResNet18, self).__init__()\n    self.features = torch.nn.Sequential(*list(fe.children()))\n    self.conv1 = nn.Conv2d(1000,3, 3,1,1)\n    self.pool =  nn.AdaptiveAvgPool2d(output_size=(1,1))\n    self.drop1 = nn.Dropout(0.3)\n    self.fc1 = nn.Linear(3,128)\n    self.drop2 = nn.Dropout(0.2)\n    self.fc2 = nn.Linear(128,1)\n    #We did not add a softmax layer here because the CrossEntropy Loss function contains a softmax, so if you want \n    #to test output, you will have to add a softmax block in addition to the model block\n    \n  def forward(self,x):\n    x = self.features(x)\n    x = self.conv1(x)\n    x = self.pool(x)\n    x = x.view(x.shape[0],3)\n    \n    x = self.drop1(x)\n    x = F.relu(self.fc1(x))\n    x = self.drop2(x)\n    x = F.sigmoid(self.fc2(x))    \n    return x\n\ncriterion_cl = nn.MSELoss()    \n\nresnet_model = ResNet18()\nresnet_model = resnet_model.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-11-08T06:26:50.479192Z","iopub.execute_input":"2021-11-08T06:26:50.479498Z","iopub.status.idle":"2021-11-08T06:26:56.300523Z","shell.execute_reply.started":"2021-11-08T06:26:50.479468Z","shell.execute_reply":"2021-11-08T06:26:56.299704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c1 = resnet_model.features\nc2 = resnet_model.conv1","metadata":{"execution":{"iopub.status.busy":"2021-11-08T06:26:56.301926Z","iopub.execute_input":"2021-11-08T06:26:56.302273Z","iopub.status.idle":"2021-11-08T06:26:56.306192Z","shell.execute_reply.started":"2021-11-08T06:26:56.302238Z","shell.execute_reply":"2021-11-08T06:26:56.305359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install torchsummary\nfrom torchsummary import summary\nsummary(resnet_model,(3,512,512))","metadata":{"execution":{"iopub.status.busy":"2021-11-08T06:26:56.307509Z","iopub.execute_input":"2021-11-08T06:26:56.308061Z","iopub.status.idle":"2021-11-08T06:27:04.382235Z","shell.execute_reply.started":"2021-11-08T06:26:56.308025Z","shell.execute_reply":"2021-11-08T06:27:04.381371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f,w = next(iter(train_loader_))\nf = f.to(device).float()\nw = w.to(device).float()\ni = c1(f)\nj = c2(i).detach()\n\nplt.figure(figsize=(8,8))\nimg_grid = torchvision.utils.make_grid(j.cpu(),normalize = True)\nplt.imshow(np.transpose(img_grid,(1,2,0)))\nplt.show()\nprint(f.dtype)\nprint(w.dtype)","metadata":{"execution":{"iopub.status.busy":"2021-11-08T06:27:04.383818Z","iopub.execute_input":"2021-11-08T06:27:04.384168Z","iopub.status.idle":"2021-11-08T06:27:06.69415Z","shell.execute_reply.started":"2021-11-08T06:27:04.384126Z","shell.execute_reply":"2021-11-08T06:27:06.693006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_eval(loader, model):\n        data = next(iter(loader))\n        i,trues = data\n        i=i.to(device)\n        trues=trues.to(device)\n        preds = model(i).cpu().detach()\n\n        preds = [1 if preds[i] >= 0.5 else 0 for i in range(len(preds))]\n\n        acc = [1 if preds[i] == trues[i] else 0 for i in range(len(preds))]\n\n        acc = np.sum(acc) / len(preds)\n    \n        return (acc * 100)","metadata":{"execution":{"iopub.status.busy":"2021-11-08T06:27:06.695466Z","iopub.execute_input":"2021-11-08T06:27:06.695864Z","iopub.status.idle":"2021-11-08T06:27:06.702563Z","shell.execute_reply.started":"2021-11-08T06:27:06.695824Z","shell.execute_reply":"2021-11-08T06:27:06.7016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model_eval(val_loader_,resnet_model))\n","metadata":{"execution":{"iopub.status.busy":"2021-11-08T06:27:06.70385Z","iopub.execute_input":"2021-11-08T06:27:06.704215Z","iopub.status.idle":"2021-11-08T06:27:08.592941Z","shell.execute_reply.started":"2021-11-08T06:27:06.704172Z","shell.execute_reply":"2021-11-08T06:27:08.591562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nfrom sklearn.metrics import accuracy_score\nhistory =[]\ntrain_acc =[]\nval_acc = []\ndef train_classifier(model, criterion, optimizer,sch,num_epochs,train_loader,val_loader):\n  \n  for epoch in range(num_epochs): \n      print(\"Epoch:\",epoch+1)\n      running_loss = 0.0\n      loop = tqdm(train_loader, leave = True)\n      for i, data in enumerate(loop):\n          inputs,labels = data\n          inputs = inputs.to(device)\n          labels = labels.to(device).to(float)\n\n          optimizer.zero_grad()\n    \n          output = model(inputs)\n          output = output.to(device).to(float).squeeze()\n          loss = criterion(output, labels)\n          \n          loss.backward()\n          optimizer.step()\n          loop.set_postfix(loss = loss.item())\n          \n          running_loss += loss.item()\n\n          if i % 100 == 99:    \n            history.append(running_loss)\n            train_acc.append(model_eval(train_loader, model))\n            val_acc.append(model_eval(val_loader, model))\n            running_loss = 0.0\n\n      sch.step()  \n      print('Epoch:', epoch+1,'LR:', sch.get_last_lr())\n      print(\"EPOCH OVER\")\n    #  train_acc = model_eval(train_loader,model)\n      with torch.no_grad():\n        test_acc = model_eval(val_loader,model)\n      print(\"Testing Accuracy\",test_acc)\n  return model","metadata":{"execution":{"iopub.status.busy":"2021-11-08T06:27:08.594212Z","iopub.execute_input":"2021-11-08T06:27:08.594553Z","iopub.status.idle":"2021-11-08T06:27:09.434381Z","shell.execute_reply.started":"2021-11-08T06:27:08.594515Z","shell.execute_reply":"2021-11-08T06:27:09.433542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.optim import lr_scheduler\ncriterion = nn.BCELoss() \nnum_epochs = 40\noptimizer = optim.SGD(resnet_model.parameters(), lr=1e-4, momentum=0.95)\nscheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\ntrain_classifier(resnet_model, criterion, optimizer, scheduler, num_epochs , train_loader_, val_loader_)","metadata":{"execution":{"iopub.status.busy":"2021-11-08T06:27:09.435681Z","iopub.execute_input":"2021-11-08T06:27:09.436041Z","iopub.status.idle":"2021-11-08T11:12:39.316216Z","shell.execute_reply.started":"2021-11-08T06:27:09.436006Z","shell.execute_reply":"2021-11-08T11:12:39.315353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_save_name = 'Flare_Classifier_25_epochs_with_metrics.pt'\npath = F\".//{model_save_name}\" \ntorch.save(resnet_model.state_dict(), path)","metadata":{"execution":{"iopub.status.busy":"2021-11-08T11:12:39.31763Z","iopub.execute_input":"2021-11-08T11:12:39.31821Z","iopub.status.idle":"2021-11-08T11:12:39.342969Z","shell.execute_reply.started":"2021-11-08T11:12:39.318171Z","shell.execute_reply":"2021-11-08T11:12:39.342119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nplt.title(\"Loss Vs Iterations\")\nplt.plot(history, color = 'blue', label = 'Training Loss')\nplt.xlabel(\"Iterations\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-08T11:12:39.34434Z","iopub.execute_input":"2021-11-08T11:12:39.344725Z","iopub.status.idle":"2021-11-08T11:12:39.495845Z","shell.execute_reply.started":"2021-11-08T11:12:39.344689Z","shell.execute_reply":"2021-11-08T11:12:39.495094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nplt.title(\"Accuracy Vs Iterations\")\nplt.plot(train_acc, color = 'blue', label = 'Training Accuracy')\nplt.plot(val_acc, color = 'yellow', label = 'Validation Accuracy')\nplt.xlabel(\"Iterations\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-08T11:12:39.498375Z","iopub.execute_input":"2021-11-08T11:12:39.498659Z","iopub.status.idle":"2021-11-08T11:12:39.657665Z","shell.execute_reply.started":"2021-11-08T11:12:39.498605Z","shell.execute_reply":"2021-11-08T11:12:39.656881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\nwith open(\"tain_acc.txt\", \"wb\") as fp:   #Pickling\n   pickle.dump(train_acc, fp)\n\nwith open(\"val_acc.txt\", \"wb\") as fp:   # Unpickling\n   pickle.dump(val_acc, fp)\n\nwith open(\"history.txt\", \"wb\") as fp:   # Unpickling\n   pickle.dump(history, fp)","metadata":{"execution":{"iopub.status.busy":"2021-11-08T11:12:39.65879Z","iopub.execute_input":"2021-11-08T11:12:39.65928Z","iopub.status.idle":"2021-11-08T11:12:39.66698Z","shell.execute_reply.started":"2021-11-08T11:12:39.659242Z","shell.execute_reply":"2021-11-08T11:12:39.666189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score\nimages, labels = next(iter(val_loader_))\nimages = images.to(device)\noutputs = resnet_model(images)\nprint(images.dtype)\nprint(labels.dtype)\nfor i in range(len(labels)):\n    outputs[i] = torch.round(outputs[i])\noutputs = outputs.cpu().detach().numpy()\ncount = 0\nscore = 0\nfor i,data in enumerate(val_loader_):\n    for i in range(len(labels)):\n        score += f1_score(labels, outputs)\n        count+=1\nprint(score/count)","metadata":{"execution":{"iopub.status.busy":"2021-11-08T11:12:39.668203Z","iopub.execute_input":"2021-11-08T11:12:39.668553Z","iopub.status.idle":"2021-11-08T11:13:00.297834Z","shell.execute_reply.started":"2021-11-08T11:12:39.668517Z","shell.execute_reply":"2021-11-08T11:13:00.296852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f,w = next(iter(train_loader_))\nf = f.to(device).float()\nw = w.to(device).float()\ni = c1(f)\nj = c2(i).detach()\n\nplt.figure(figsize=(16,8))\nimg_grid = torchvision.utils.make_grid(f[:16].cpu(),normalize = True)\nplt.imshow(np.transpose(img_grid,(1,2,0)))\nplt.show()\n\nplt.figure(figsize=(16,8))\nimg_grid = torchvision.utils.make_grid(j[:16].cpu(),normalize = True)\nplt.imshow(np.transpose(img_grid,(1,2,0)))\nplt.show()\n\nout = resnet_model(f)\nprint(out)","metadata":{"execution":{"iopub.status.busy":"2021-11-08T11:13:00.299157Z","iopub.execute_input":"2021-11-08T11:13:00.299488Z","iopub.status.idle":"2021-11-08T11:13:02.094409Z","shell.execute_reply.started":"2021-11-08T11:13:00.299451Z","shell.execute_reply":"2021-11-08T11:13:02.093414Z"},"trusted":true},"execution_count":null,"outputs":[]}]}